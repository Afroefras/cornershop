{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/efraflores/Desktop/EF/Corner/Brands/New_SoM'\n",
    "CPG_NAME = 'Colgate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "from unicodedata import normalize\n",
    "from pandas import DataFrame, read_csv\n",
    "from IPython.display import clear_output\n",
    "from re import sub, search, UNICODE, I\n",
    "\n",
    "class SoM:\n",
    "    def __init__(self, base_dir: str, cpg_name: str, colab: bool=False) -> None:\n",
    "        self.cpg_name = cpg_name.strip().replace(' ','_').title()\n",
    "        if colab: self.base_dir = Path(base_dir)\n",
    "        else: self.base_dir = Path(base_dir).joinpath(cpg_name)\n",
    "        self.cpg_data = self.base_dir.joinpath(f'{self.cpg_name}_Tableau.csv')\n",
    "        if colab: self.brand_cpg = self.base_dir.joinpath('brand_cpg.csv')\n",
    "        else: self.brand_cpg = self.base_dir.parent.joinpath('brand_cpg.csv')\n",
    "        for search_file in [self.cpg_data, self.brand_cpg]:\n",
    "            if not search_file.is_file(): \n",
    "                search_name = ''.join(str(search_file).split('/')[-1])\n",
    "                search_path = ''.join(str(search_file).split('/')[:-1])\n",
    "                print(f'There should be a file called: {search_name} at path:\\n{search_path}\\n\\nAdd this file and try again!\\n')\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f'CPG:\\t{self.cpg_name}\\nPath:\\t{self.base_dir}\\nFile:\\t{self.cpg_data}\\nBrand-CPG:\\t{self.brand_cpg}'\n",
    "\n",
    "    def clean_text_column(self, text: str, pattern: str=\"[^a-zA-Z0-9\\s]\") -> str:\n",
    "        # Remove special characters like symbols or accents áäâàã\n",
    "        clean = normalize('NFD', str(text).replace('\\n', ' \\n ')).encode('ascii', 'ignore')\n",
    "        clean = sub(pattern, ' ', clean.decode('utf-8'), flags=UNICODE).strip().lower()\n",
    "        # Two or more spaces will be replaced with one\n",
    "        clean = sub(r'\\s{2,}',' ', clean)\n",
    "        # Clean any null string and replace spaces with underscore\n",
    "        clean = sub(r'^nan$','', clean).replace(' ','_')\n",
    "        return clean\n",
    "\n",
    "    def read_tableau_data(self) -> DataFrame:\n",
    "        df = read_csv(self.cpg_data, sep='\\t', encoding='utf-16', low_memory=False)\n",
    "        # Drop last \"Total\" row\n",
    "        df = df.iloc[:-1,:].copy()\n",
    "        # Clean every column name\n",
    "        df.columns = map(self.clean_text_column, df.columns)\n",
    "        return df\n",
    "\n",
    "    def find_brand(self, df: DataFrame, brand_col: str='brand_filter', find_pattern: str='(?P<brand_name>.*)(?=\\()\\((?P<brand_id>\\d+)') -> DataFrame:\n",
    "        found = DataFrame([search(find_pattern, x, flags=I).groupdict() if search(find_pattern,x)!=None else {'brand_id': 0} for x in df[brand_col]], index=df.index)\n",
    "        df = df.join(found)\n",
    "        return df\n",
    "\n",
    "    def create_catalog(self, category_col: str='category_en', brand_col:str='brand_id', product_col: str='product_name', cols_keep: list=['category_id','category_en','product_id','product_name','barcodes','package','brand_filter'], cols_catalog=['brand_id','cpg_names'], export=False) -> DataFrame:\n",
    "        # Without duplicates of parameter cols\n",
    "        df = self.read_tableau_data()[cols_keep].drop_duplicates().reset_index(drop=True)\n",
    "        df = self.find_brand(df)\n",
    "        # Import the brand->CPG catalog\n",
    "        bc = read_csv(self.brand_cpg, low_memory=False).drop_duplicates(brand_col).fillna(0)\n",
    "        bc[brand_col] = bc[brand_col].astype(int)\n",
    "        bc['brand'] = bc['brand'].astype(str).str.strip()\n",
    "        # Merge it with brand_id\n",
    "        df = df.merge(bc[cols_catalog].astype(str), on=brand_col, how='left').fillna('EMPTY')\n",
    "        # Create a column to group competitors\n",
    "        df['CPG'] = df[cols_catalog[-1]].map(lambda x: self.cpg_name if search(self.cpg_name, self.clean_text_column(str(x)), flags=I)!=None else 'Comp')\n",
    "        # Same Cornershop category name as the default category name for the CPG\n",
    "        df['category_CPG'] = df[category_col]\n",
    "        # First word of the product name as the default sub-category name for the CPG\n",
    "        df['sub_category_CPG'] = df[product_col].map(lambda x: self.clean_text_column(str(x).strip().split()[0]).title())\n",
    "        # Sort in the correct format order\n",
    "        catalog = df[['CPG']+cols_catalog[-1:]+cols_keep+['brand_id','brand_name']+['category_CPG','sub_category_CPG']].rename(columns={cols_catalog[-1]:'CPG_real'})\n",
    "        catalog.sort_values(['CPG',brand_col, category_col], inplace=True)\n",
    "        # Export it as csv\n",
    "        if export: catalog.to_csv(self.base_dir.joinpath(f'{self.cpg_name}_catalog.csv'), index=False, sep='\\t', encoding='utf-16')\n",
    "        return catalog\n",
    "\n",
    "    def predict_category(self, export: bool=False) -> DataFrame:\n",
    "        catalog = read_csv(self.base_dir.joinpath(f'{self.cpg_name}_catalog.csv'), low_memory=False)\n",
    "        \n",
    "\n",
    "    def clean_tableau_data(self, col_month_year: str='month', to_drop: list=['avg_ticket','found_rate','fulfillment','frequency']) -> DataFrame:\n",
    "        df = self.read_tableau_data().drop(columns=to_drop)\n",
    "        # Split every row by its space \"july 2021\" --> ['july','2021']\n",
    "        df[col_month_year] = df[col_month_year].str.split()\n",
    "        # Get the last element \n",
    "        df['year'] = df[col_month_year].map(lambda x: x[-1])\n",
    "        # Get the first 3 characters from the 1st elem ['july','2021'] --> 'jul'\n",
    "        df['month'] = df[col_month_year].str[0].str[:3]\n",
    "        # Create the list+dict to map \"jul\" --> \"07_jul\"\n",
    "        list_month = ['ene','feb','mar','abr','may','jun','jul','ago','sep','oct','nov','dic']\n",
    "        dict_month = dict(zip(list_month, map(lambda x: str(x[0]).zfill(2)+'_'+x[1], zip(range(1,13),list_month))))\n",
    "        df['month'] = df['month'].map(dict_month)\n",
    "        return df\n",
    "\n",
    "    def cool_print(self, text: str, sleep_time: float=0.01, by_word: bool=False) -> None:\n",
    "        # Print as typing\n",
    "        acum = ''\n",
    "        for x in text.split() if by_word else text:\n",
    "            acum += x+' ' if by_word else x\n",
    "            clear_output(wait=True)\n",
    "            sleep(sleep_time*(9 if by_word else 1))\n",
    "            print(acum)\n",
    "        sleep(0.9)\n",
    "\n",
    "    def user_exit(self) -> bool:\n",
    "        # Ask user if he/she/they want to exit or continue\n",
    "        user_response = ''\n",
    "        while user_response not in ['y','n','Y','N']:\n",
    "            user_response = input('Enter \"y\" to continue or \"n\" to exit\\n')\n",
    "        else: \n",
    "            return user_response in ('n','N')\n",
    "\n",
    "    def create_som(self, kwargs_catalog: Dict={}, kwargs_tableau: Dict={}) -> None:\n",
    "        # Connect all methods to create the SoM data interacting with an user\n",
    "        self.cool_print(f'Welcome to SoM Creator!\\nWe are about to build the data for {self.cpg_name.upper()}!\\nFirst step:\\tBrand + Category catalog!')\n",
    "        # Continue?\n",
    "        if self.user_exit():\n",
    "            self.cool_print('Have a nice day!')\n",
    "            return None\n",
    "        # Ask for the creation of catalog\n",
    "        ask_catalog = ''\n",
    "        while ask_catalog not in ['y','n','Y','N']:\n",
    "            ask_catalog = input('Do you want to create a catalog? y/n\\n')\n",
    "        else: \n",
    "            # Create catalog\n",
    "            if ask_catalog in ('y','Y'): \n",
    "                catalog = self.create_catalog(export=True, **kwargs_catalog)\n",
    "                self.cool_print(f'Catalog was created at path:\\n{self.base_dir}\\nnamed: {self.cpg_name}_catalog.csv')\n",
    "            else:\n",
    "                # Import it\n",
    "                read_csv_params = {'sep':'\\t', 'encoding':'utf-16'}\n",
    "                try: \n",
    "                    catalog = read_csv(self.base_dir.joinpath(f'{self.cpg_name}_catalog.csv'), low_memory=False, **read_csv_params)\n",
    "                    self.cool_print(f'{self.cpg_name}_catalog.csv was found at path:\\n{self.base_dir}')\n",
    "                # UTF-16 error\n",
    "                except UnicodeError:\n",
    "                    catalog = read_csv(self.base_dir.joinpath(f'{self.cpg_name}_catalog.csv'), low_memory=False)\n",
    "                    self.cool_print(f'{self.cpg_name}_catalog.csv was found at path:\\n{self.base_dir}')\n",
    "                # 404, exit\n",
    "                except FileNotFoundError:\n",
    "                    self.cool_print(f'File with name {self.cpg_name}_catalog.csv was not found at path:\\n{self.base_dir}\\n\\nAdd it and try again!\\nHave a nice day!')\n",
    "                    return None        \n",
    "        # Merge data with catalog\n",
    "        self.cool_print('Now, it is time to merge the data with the catalog')\n",
    "        # Continue?\n",
    "        if self.user_exit():\n",
    "            self.cool_print('Have a nice day!')\n",
    "            return None\n",
    "        # Read data and merge it\n",
    "        df = self.clean_tableau_data(**kwargs_tableau).astype(str)\n",
    "        df = df.merge(catalog.astype(str), on=['product_id'], suffixes=('_tableau',''))\n",
    "        df['brand_name'] = df['brand_name'].astype(str).str.strip()\n",
    "        # Export it, process finished\n",
    "        df.to_csv(self.base_dir.joinpath(f'{self.cpg_name}_som.csv'), index=False, sep='\\t', encoding='utf-16')\n",
    "        self.cool_print(f'A file named: {self.cpg_name}_som.csv was created at path:\\n{self.base_dir}\\n\\nHave a nice day!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SoM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A file named: Colgate_som.csv was created at path:\n",
      "/Users/efraflores/Desktop/EF/Corner/Brands/New_SoM/Colgate\n",
      "\n",
      "Have a nice day!\n"
     ]
    }
   ],
   "source": [
    "SoM(BASE_DIR, CPG_NAME).create_som()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd073f3038b8337706d4c7d775204fb19bddc277721f52eb60f8c4b0892f2184"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
