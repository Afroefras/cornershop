{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the most ordered custom-products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/efraflores/Desktop/EF/Corner/Catalog/Custom_products/data'\n",
    "FILE_NAME = 'custom_products.csv'\n",
    "STOPWORDS = [\n",
    "    'heb','empty','si','no','ni','sin','que','q','un','una','uno','el','la','los',\n",
    "    'en','de','y','mi','para','por','favor','porfavor','porfa','has','re','esten',\n",
    "    'muy','ma','lo','se','sea','solo','este','do','con','hay','gracia','pieza','gr',\n",
    "    'gramo','kg','kilo','marca','bolsa','caja','paquete','grande','sabor','color',\n",
    "    'rojo','blanco','traer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from numpy import nan\n",
    "from emoji import demojize\n",
    "from re import sub, UNICODE\n",
    "from unicodedata import normalize\n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class CustomProducts:\n",
    "    def __init__(self, base_dir: str, file_name: str, stopw: list) -> None:\n",
    "        '''\n",
    "        Inicializa la clase recibiendo un directorio un nombre de archivo\n",
    "        '''\n",
    "        # Obtiene un directorio como texto y convertirlo a tipo Path para unir directorios, buscar archivos, etc.\n",
    "        self.base_dir = Path(base_dir)\n",
    "        # Guarda el nombre del archivo como atributo\n",
    "        self.file_name = file_name\n",
    "        # Guarda la lista de stopwords para omitir\n",
    "        self.stopwords = stopw\n",
    "\n",
    "        # Concatena el directorio y el nombre del archivo\n",
    "        self.file_path = self.base_dir.joinpath(self.file_name)\n",
    "        # Revisa si el archivo existe\n",
    "        if not self.file_path.is_file(): print(f'It should be a file called \"{self.file_name}\" at\\n{self.base_dir}\\n\\nBut there is not, add it and try again')\n",
    "\n",
    "\n",
    "    def clean_text(self, text: str, rem_stop: list, pattern: str=\"[^a-zA-Z\\s]\", lower: bool=True, emoji: bool=True, to_singular: bool=True) -> str: \n",
    "        '''\n",
    "        Limpieza de texto\n",
    "        '''\n",
    "        # \"Traduce\" emojis, ej: 🇲🇽 --> :Mexico:\n",
    "        if emoji: text = demojize(text)\n",
    "\n",
    "        # Reemplazar acentos: áàäâã --> a\n",
    "        clean = normalize('NFD', str(text).replace('\\n', ' \\n ')).encode('ascii', 'ignore')\n",
    "        # Omitir caracteres especiales !\"#$%&/()=...\n",
    "        clean = sub(pattern, ' ', clean.decode('utf-8'), flags=UNICODE)\n",
    "\n",
    "        # Mantener sólo un espacio\n",
    "        clean = sub(r'\\s{2,}', ' ', clean.strip())\n",
    "\n",
    "        # Minúsculas si el parámetro lo indica\n",
    "        if lower: clean = clean.lower()\n",
    "        # Omitir la última \"s\" si el parámetro lo indica\n",
    "        if to_singular: clean = sub('s\\s',' ',clean+' ')\n",
    "\n",
    "        # Omitir las stopwords indicadas\n",
    "        clean = ' '.join([x for x in clean.split() if x not in rem_stop])\n",
    "\n",
    "        # Si el registro estaba vacío, indicar nulo\n",
    "        if clean in ('','nan'): clean = nan\n",
    "        return clean\n",
    "\n",
    "    def data_wrangling(self, col: str='description', top_n=100, **kwargs) -> DataFrame:\n",
    "        # Obtiene el csv\n",
    "        df = read_csv(self.file_path)\n",
    "        df[f'{col}_clean'] = df[col].map(lambda x: self.clean_text(x, rem_stop=self.stopwords)).fillna('')\n",
    "        cv = CountVectorizer(max_features=top_n, **kwargs)\n",
    "        cv_fit = cv.fit_transform(df[f'{col}_clean'])\n",
    "        top = dict(zip(cv.get_feature_names(), cv_fit.toarray().sum(axis=0)))\n",
    "        top = DataFrame(top, index=['word_count']).T.sort_values('word_count', ascending=False)\n",
    "        return top\n",
    "\n",
    "cp = CustomProducts(BASE_DIR, FILE_NAME, STOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>queso</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pan</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pavo</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rebanada</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pechuga</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chocolate</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pechuga pavo</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bote</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crema</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pollo</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oaxaca</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barra</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verde</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leche</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>granel</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mandarina</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vainilla</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papa</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papaya</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lee</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chile</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sara</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sara lee</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congelado</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queso oaxaca</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tortilla</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negra</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manchego</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>farmacia</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word_count\n",
       "queso                 44\n",
       "pan                   37\n",
       "pavo                  24\n",
       "natural               20\n",
       "rebanada              20\n",
       "pechuga               20\n",
       "chocolate             17\n",
       "pechuga pavo          17\n",
       "bote                  16\n",
       "crema                 15\n",
       "pollo                 13\n",
       "oaxaca                13\n",
       "barra                 13\n",
       "verde                 13\n",
       "leche                 13\n",
       "granel                13\n",
       "mandarina             13\n",
       "vainilla              11\n",
       "papa                  11\n",
       "papaya                11\n",
       "lee                   11\n",
       "chile                 11\n",
       "sara                  11\n",
       "sara lee              11\n",
       "congelado             10\n",
       "queso oaxaca          10\n",
       "tortilla               9\n",
       "negra                  9\n",
       "manchego               9\n",
       "farmacia               9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n = cp.data_wrangling(top_n=30, ngram_range=(1,3))\n",
    "top_n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd073f3038b8337706d4c7d775204fb19bddc277721f52eb60f8c4b0892f2184"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
