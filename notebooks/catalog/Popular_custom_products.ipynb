{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the most ordered custom-products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/efraflores/Desktop/EF/Corner/Catalog/Custom_products/data'\n",
    "FILE_NAME = 'custom_products.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from numpy import nan\n",
    "from emoji import demojize\n",
    "from re import sub, UNICODE\n",
    "from unicodedata import normalize\n",
    "from pandas import DataFrame, Series, read_csv, cut, to_datetime\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class CustomProducts:\n",
    "    def __init__(self, base_dir, file_name) -> None:\n",
    "        '''\n",
    "        Inicializa la clase recibiendo un directorio un nombre de archivo\n",
    "        '''\n",
    "        # Obtiene un directorio como texto y convertirlo a tipo Path para unir directorios, buscar archivos, etc.\n",
    "        self.base_dir = Path(base_dir)\n",
    "        # Guarda el nombre del archivo como atributo\n",
    "        self.file_name = file_name\n",
    "\n",
    "        # Concatena el directorio y el nombre del archivo\n",
    "        self.file_path = self.base_dir.joinpath(self.file_name)\n",
    "        # Revisa si el archivo existe\n",
    "        if not self.file_path.is_file(): print(f'It should be a file called \"{self.file_name}\" at\\n{self.base_dir}\\n\\nBut there is not, add it and try again')\n",
    "\n",
    "\n",
    "    def two_char(self, n: float) -> str:\n",
    "        '''\n",
    "        Funci칩n para convertir float: 1.0 --> str: '01'\n",
    "        '''\n",
    "        return str(int(n)).zfill(2)\n",
    "\n",
    "\n",
    "    def create_bins(self, df: DataFrame, col: str, bins: list, lower_limit=-1, upper_limit=1000) -> Series:\n",
    "        '''\n",
    "        Recibiendo los cortes, recibe una columna num칠rica y crea rangos tipo \"00\", \"01 a 05\", \">=6\"\n",
    "        '''\n",
    "        # Crear rangos\n",
    "        df[f'{col}_range'] = cut(df[col], bins=[lower_limit]+bins+[upper_limit])\n",
    "        # Convertirlo a texto: [1.0 - 5.0] --> '01 a 05'\n",
    "        df[f'{col}_range'] = df[f'{col}_range'].map(lambda x: self.two_char(x.left+1)+' a '+self.two_char(x.right) if x!=nan else nan)\n",
    "\n",
    "        # Corregir algunas etiquetas como: '01 a 01'-->'01' y tambi칠n '03 a upper_limit'-->'>= 03'\n",
    "        last_cut = self.two_char(bins[-1]+1)\n",
    "        df[[f'{col}_range']] = df[[f'{col}_range']].replace({\n",
    "            **{last_cut+f' a {upper_limit}': '>= '+last_cut},\n",
    "            **{self.two_char(x)+' a '+self.two_char(x): self.two_char(x) for x in bins}\n",
    "        })\n",
    "        # No perder de vista los valores ausentes: \"La falta de informaci칩n tambi칠n es informaci칩n\"\n",
    "        df[f'{col}_range'] = df[f'{col}_range'].map(lambda x: nan if str(x)=='nan' else str(x))\n",
    "\n",
    "        return df[f'{col}_range']\n",
    "\n",
    "\n",
    "    def date_vars(self, df: DataFrame, date_col: str='date', hours_bin: list=[9,12,14,17,20], **kwargs) -> DataFrame: \n",
    "        '''\n",
    "        Crear variables de fecha: a침o, trimestre, mes, hora y rangos de hora\n",
    "        '''\n",
    "        # Convertir a tipo datetime\n",
    "        df[date_col] = to_datetime(df[date_col], **kwargs)\n",
    "\n",
    "        # Para extraer la divisi칩n de a침o\n",
    "        df[f'{date_col}_year'] = df[date_col].dt.year.map(int).map(str)\n",
    "        # Trimestre a dos caracteres\n",
    "        df[f'{date_col}_quarter'] = df[date_col].dt.quarter.map(self.two_char)+'Q'\n",
    "        # Mes\n",
    "        df[f'{date_col}_month'] = df[date_col].dt.month\n",
    "        # Semana a dos caracteres\n",
    "        df[f'{date_col}_week'] = df[date_col].dt.isocalendar().week.map(self.two_char)+'W'\n",
    "\n",
    "        # Concatenar el a침o, tanto trimestre como con el mes\n",
    "        df[f'{date_col}_yearquarter'] = df[f'{date_col}_year']+' - '+df[f'{date_col}_quarter']\n",
    "        df[f'{date_col}_yearmonth'] = df[f'{date_col}_year']+' - '+df[f'{date_col}_month'].map(self.two_char)+'M'\n",
    "        df[f'{date_col}_yearweek'] = df[f'{date_col}_year']+' - '+df[f'{date_col}_week']\n",
    "\n",
    "        # Create the list+dict to map \"jul\" --> \"07_jul\"\n",
    "        list_month = ['ene','feb','mar','abr','may','jun','jul','ago','sep','oct','nov','dic']\n",
    "        dict_month = dict(zip(\n",
    "            range(1,13), \n",
    "            map(lambda x: x[0]+'_'+x[-1], zip(map(self.two_char, range(1,13)),list_month))\n",
    "        ))\n",
    "        df[f'{date_col}_month'] = df[f'{date_col}_month'].map(dict_month)\n",
    "\n",
    "        # D칤a de la semana, s칩lo los primeros 3 caracteres\n",
    "        df[f'{date_col}_weekday'] = df[date_col].dt.day_name().str[:3]\n",
    "\n",
    "        # Hora\n",
    "        df[f'{date_col}_hour'] = df[date_col].dt.hour\n",
    "        # Crear rangos de hora\n",
    "        df[f'{date_col}_hour_range'] = self.create_bins(df, f'{date_col}_hour', bins=hours_bin)\n",
    "\n",
    "        # Mantener s칩lo la fecha\n",
    "        df[date_col] = df[date_col].dt.date\n",
    "        return df\n",
    "\n",
    "    def clean_text(self, text: str, rem_stop: list, pattern: str=\"[^a-zA-Z0-9\\s\\-\\/]\", lower: bool=True, emoji: bool=True, to_singular: bool=True) -> str: \n",
    "        '''\n",
    "        Limpieza de texto\n",
    "        '''\n",
    "        # \"Traduce\" emojis, ej: 游쓇릖 --> :Mexico:\n",
    "        if emoji: text = demojize(text)\n",
    "\n",
    "        # Reemplazar acentos: 치먞뱪뭮 --> a\n",
    "        clean = normalize('NFD', str(text).replace('\\n', ' \\n ')).encode('ascii', 'ignore')\n",
    "        # Omitir caracteres especiales !\"#$%&/()=...\n",
    "        clean = sub(pattern, ' ', clean.decode('utf-8'), flags=UNICODE)\n",
    "\n",
    "        # Mantener s칩lo un espacio\n",
    "        clean = sub(r'\\s{2,}', ' ', clean.strip())\n",
    "\n",
    "        # Min칰sculas si el par치metro lo indica\n",
    "        if lower: clean = clean.lower()\n",
    "        # Omitir la 칰ltima \"s\" si el par치metro lo indica\n",
    "        if to_singular: clean = sub('s\\s',' ',clean+' ')\n",
    "\n",
    "        # Omitir las stopwords indicadas\n",
    "        clean = ' '.join([x for x in clean.split() if x not in rem_stop])\n",
    "\n",
    "        # Si el registro estaba vac칤o, indicar nulo\n",
    "        if clean in ('','nan'): clean = nan\n",
    "        return clean\n",
    "\n",
    "    def data_wrangling(self, stopw: list, cols_to_split: list=['store','branch','product','brand','category'], cols_to_merge: list=['category','brand','product','custom_request'], custom_req_col: str='custom_request', **kwargs) -> DataFrame:\n",
    "        # Obtiene el csv\n",
    "        df = read_csv(self.file_path, **kwargs)\n",
    "\n",
    "        # Separa cada columna en dos a partir del primer caracter \"-\"\n",
    "        for col in cols_to_split: df[[f'{col}_id',col]] = df[col].str.split('-', n=1, expand=True)\n",
    "        # Crea las variables de fecha\n",
    "        df = self.date_vars(df, **kwargs)\n",
    "\n",
    "        # Une las palabras para no asumir por ejemplo la categor칤a \"fruta fresca\" como dos palabras sino una\n",
    "        for col in cols_to_merge: \n",
    "            # Con excepci칩n de la columna que indica el custom_request\n",
    "            if col==custom_req_col: pass\n",
    "            else: df[col] = df[col].map(lambda x: str(x).strip().replace(' ',''))\n",
    "\n",
    "        # Une las columnas que se indiquen en el par치metro para limpiar el texto\n",
    "        df['text'] = df[cols_to_merge].apply(' '.join, axis=1).map(lambda x: self.clean_text(x,rem_stop=stopw))\n",
    "        return df\n",
    "\n",
    "    def top_words(self, df: DataFrame, col: str='text', top_n: int=100, **kwargs) -> DataFrame:\n",
    "        cv = CountVectorizer(max_features=top_n, **kwargs)\n",
    "        cv_fit = cv.fit_transform(df[col])\n",
    "        top = dict(zip(cv.get_feature_names(), cv_fit.toarray().sum(axis=0)))\n",
    "        top = DataFrame(top, index=['word_count']).T.sort_values('word_count', ascending=False)\n",
    "        return top\n",
    "\n",
    "\n",
    "cp = CustomProducts(BASE_DIR, FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>order_id</th>\n",
       "      <th>city</th>\n",
       "      <th>zone</th>\n",
       "      <th>store</th>\n",
       "      <th>branch</th>\n",
       "      <th>category</th>\n",
       "      <th>brand</th>\n",
       "      <th>product</th>\n",
       "      <th>custom_request</th>\n",
       "      <th>...</th>\n",
       "      <th>date_quarter</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_week</th>\n",
       "      <th>date_yearquarter</th>\n",
       "      <th>date_yearmonth</th>\n",
       "      <th>date_yearweek</th>\n",
       "      <th>date_weekday</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date_hour_range</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>2021-10-23</td>\n",
       "      <td>44068056</td>\n",
       "      <td>Monterrey</td>\n",
       "      <td>Suroeste</td>\n",
       "      <td>HEB</td>\n",
       "      <td>eFC Aaron Saenz</td>\n",
       "      <td>Verdurasyfrutasenvasadas</td>\n",
       "      <td>HEB</td>\n",
       "      <td>Freshmel칩ncortado</td>\n",
       "      <td>En dos trastes de 300</td>\n",
       "      <td>...</td>\n",
       "      <td>04Q</td>\n",
       "      <td>10_oct</td>\n",
       "      <td>42W</td>\n",
       "      <td>2021 - 04Q</td>\n",
       "      <td>2021 - 10M</td>\n",
       "      <td>2021 - 42W</td>\n",
       "      <td>Sat</td>\n",
       "      <td>20</td>\n",
       "      <td>18 a 20</td>\n",
       "      <td>verdurasyfrutasenvasada freshmeloncortado tras...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows 칑 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  order_id       city      zone store            branch  \\\n",
       "2925  2021-10-23  44068056  Monterrey  Suroeste   HEB   eFC Aaron Saenz   \n",
       "\n",
       "                      category brand            product  \\\n",
       "2925  Verdurasyfrutasenvasadas   HEB  Freshmel칩ncortado   \n",
       "\n",
       "             custom_request  ... date_quarter date_month date_week  \\\n",
       "2925  En dos trastes de 300  ...          04Q     10_oct       42W   \n",
       "\n",
       "     date_yearquarter date_yearmonth date_yearweek date_weekday date_hour  \\\n",
       "2925       2021 - 04Q     2021 - 10M    2021 - 42W          Sat        20   \n",
       "\n",
       "     date_hour_range                                               text  \n",
       "2925         18 a 20  verdurasyfrutasenvasada freshmeloncortado tras...  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_stopwords = ['heb','empty','si','no','ni','sin','que','q','un','una','uno','el','la','los','en','de','y','mi','para','por','favor','porfavor','porfa','has','re','esten','muy','ma','lo','se','sea','solo','este','do','con','hay','gracia','pieza']\n",
    "df = cp.data_wrangling(stopw=custom_stopwords)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>frutasfresca</th>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verdurasfresca</th>\n",
       "      <td>1377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verde</th>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aguacatehasssupremo</th>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platano</th>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jamondepavo</th>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carnedere</th>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maduro</th>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rebanada</th>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papayamaradol</th>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grande</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delgada</th>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>media</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paquete</th>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caducidad</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uvablancasupremasinsemilla</th>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queso</th>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verdurasyfrutasenvasada</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bolsa</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kilo</th>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanrafael</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medio</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pescado</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fecha</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>madura</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>melonchino</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suprememilanesadepulpanegra</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papaya</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charola</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pollo</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mitad</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chica</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomateguajesupremo</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             word_count\n",
       "frutasfresca                       1539\n",
       "verdurasfresca                     1377\n",
       "verde                               556\n",
       "aguacatehasssupremo                 538\n",
       "platano                             529\n",
       "jamondepavo                         370\n",
       "carnedere                           363\n",
       "maduro                              363\n",
       "rebanada                            349\n",
       "papayamaradol                       290\n",
       "grande                              258\n",
       "delgada                             254\n",
       "media                               192\n",
       "paquete                             190\n",
       "caducidad                           171\n",
       "uvablancasupremasinsemilla          157\n",
       "queso                               149\n",
       "verdurasyfrutasenvasada             147\n",
       "bolsa                               136\n",
       "kilo                                133\n",
       "sanrafael                           127\n",
       "medio                               124\n",
       "pescado                             117\n",
       "fecha                               117\n",
       "madura                              112\n",
       "melonchino                          109\n",
       "suprememilanesadepulpanegra         106\n",
       "papaya                              105\n",
       "charola                             103\n",
       "pollo                                99\n",
       "mitad                                98\n",
       "chica                                91\n",
       "tomateguajesupremo                   88"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.top_words(df, top_n=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd073f3038b8337706d4c7d775204fb19bddc277721f52eb60f8c4b0892f2184"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
