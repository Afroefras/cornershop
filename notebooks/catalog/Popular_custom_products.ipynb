{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the most ordered custom-products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/efraflores/Desktop/EF/Corner/Catalog/Custom_products/data'\n",
    "FILE_NAME = 'custom_products.csv'\n",
    "STOPWORDS = [\n",
    "    'heb','empty','si','no','ni','sin','que','q','un','una','uno','el','la','los',\n",
    "    'en','de','y','mi','para','por','favor','porfavor','porfa','has','re','esten',\n",
    "    'muy','ma','lo','se','sea','solo','este','do','con','hay','gracia','pieza','gr',\n",
    "    'gramo','kg','kilo','marca','bolsa','caja','paquete','grande','sabor','color',\n",
    "    'rojo','blanco','traer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from numpy import nan\n",
    "from emoji import demojize\n",
    "from re import sub, UNICODE\n",
    "from unicodedata import normalize\n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class CustomProducts:\n",
    "    def __init__(self, base_dir: str, file_name: str, stopw: list) -> None:\n",
    "        '''\n",
    "        Inicializa la clase recibiendo un directorio un nombre de archivo\n",
    "        '''\n",
    "        # Obtiene un directorio como texto y convertirlo a tipo Path para unir directorios, buscar archivos, etc.\n",
    "        self.base_dir = Path(base_dir)\n",
    "        # Guarda el nombre del archivo como atributo\n",
    "        self.file_name = file_name\n",
    "        # Guarda la lista de stopwords para omitir\n",
    "        self.stopwords = stopw\n",
    "\n",
    "        # Concatena el directorio y el nombre del archivo\n",
    "        self.file_path = self.base_dir.joinpath(self.file_name)\n",
    "        # Revisa si el archivo existe\n",
    "        if not self.file_path.is_file(): print(f'It should be a file called \"{self.file_name}\" at\\n{self.base_dir}\\n\\nBut there is not, add it and try again')\n",
    "\n",
    "\n",
    "    def clean_text(self, text: str, rem_stop: list, pattern: str=\"[^a-zA-Z\\s]\", lower: bool=True, emoji: bool=True, to_singular: bool=True) -> str: \n",
    "        '''\n",
    "        Limpieza de texto\n",
    "        '''\n",
    "        # \"Traduce\" emojis, ej: 游쓇릖 --> :Mexico:\n",
    "        if emoji: text = demojize(text)\n",
    "\n",
    "        # Reemplazar acentos: 치먞뱪뭮 --> a\n",
    "        clean = normalize('NFD', str(text).replace('\\n', ' \\n ')).encode('ascii', 'ignore')\n",
    "        # Omitir caracteres especiales !\"#$%&/()=...\n",
    "        clean = sub(pattern, ' ', clean.decode('utf-8'), flags=UNICODE)\n",
    "\n",
    "        # Mantener s칩lo un espacio\n",
    "        clean = sub(r'\\s{2,}', ' ', clean.strip())\n",
    "\n",
    "        # Min칰sculas si el par치metro lo indica\n",
    "        if lower: clean = clean.lower()\n",
    "        # Omitir la 칰ltima \"s\" si el par치metro lo indica\n",
    "        if to_singular: clean = sub('s\\s',' ',clean+' ')\n",
    "\n",
    "        # Omitir las stopwords indicadas\n",
    "        clean = ' '.join([x for x in clean.split() if x not in rem_stop])\n",
    "\n",
    "        # Si el registro estaba vac칤o, indicar nulo\n",
    "        if clean in ('','nan'): clean = nan\n",
    "        return clean\n",
    "\n",
    "    def data_wrangling(self, col: str='description', top_n=100, **kwargs) -> DataFrame:\n",
    "        # Obtiene el csv\n",
    "        df = read_csv(self.file_path)\n",
    "        df[f'{col}_clean'] = df[col].map(lambda x: self.clean_text(x, rem_stop=self.stopwords)).fillna('')\n",
    "        cv = CountVectorizer(max_features=top_n, **kwargs)\n",
    "        cv_fit = cv.fit_transform(df[f'{col}_clean'])\n",
    "        top = dict(zip(cv.get_feature_names(), cv_fit.toarray().sum(axis=0)))\n",
    "        top = DataFrame(top, index=['word_count']).T.sort_values('word_count', ascending=False)\n",
    "        return top\n",
    "\n",
    "cp = CustomProducts(BASE_DIR, FILE_NAME, STOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>queso</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pan</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pavo</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rebanada</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pechuga</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chocolate</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pechuga pavo</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bote</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crema</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pollo</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oaxaca</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barra</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verde</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leche</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>granel</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mandarina</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vainilla</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papa</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papaya</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lee</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chile</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sara</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sara lee</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congelado</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queso oaxaca</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tortilla</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negra</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manchego</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>farmacia</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word_count\n",
       "queso                 44\n",
       "pan                   37\n",
       "pavo                  24\n",
       "natural               20\n",
       "rebanada              20\n",
       "pechuga               20\n",
       "chocolate             17\n",
       "pechuga pavo          17\n",
       "bote                  16\n",
       "crema                 15\n",
       "pollo                 13\n",
       "oaxaca                13\n",
       "barra                 13\n",
       "verde                 13\n",
       "leche                 13\n",
       "granel                13\n",
       "mandarina             13\n",
       "vainilla              11\n",
       "papa                  11\n",
       "papaya                11\n",
       "lee                   11\n",
       "chile                 11\n",
       "sara                  11\n",
       "sara lee              11\n",
       "congelado             10\n",
       "queso oaxaca          10\n",
       "tortilla               9\n",
       "negra                  9\n",
       "manchego               9\n",
       "farmacia               9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n = cp.data_wrangling(top_n=30, ngram_range=(1,3))\n",
    "top_n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd073f3038b8337706d4c7d775204fb19bddc277721f52eb60f8c4b0892f2184"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
