{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparar catálogo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/efraflores/Desktop/EF/Corner/Catalog/Decathlon'\n",
    "FILE_MX = 'Decathlon_MX.csv'\n",
    "FILE_CL = 'Decathlon_CL.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control de datos\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Ingeniería de variables\n",
    "from numpy import nan\n",
    "from re import sub, UNICODE\n",
    "from unicodedata import normalize\n",
    "from difflib import get_close_matches\n",
    "from pandas import DataFrame, read_csv, options\n",
    "options.mode.chained_assignment = None\n",
    "\n",
    "class CompareCatalog:\n",
    "    def __init__(self, base_dir:str, file_mx: str, file_cl: str) -> None:\n",
    "        '''\n",
    "        Obtener un directorio como texto y convertirlo a tipo Path para unir directorios, buscar archivos, etc.\n",
    "        '''\n",
    "        self.base_dir = Path(base_dir)\n",
    "        # Definir la ruta completa para leer cada archivo\n",
    "        self.file_mx = self.base_dir.joinpath(file_mx)\n",
    "        self.file_cl = self.base_dir.joinpath(file_cl)\n",
    "        # Verificar que existe el archivo en el directorio\n",
    "        for file_path in [self.file_mx, self.file_cl]:\n",
    "            if not file_path.is_file():\n",
    "                file_name = ''.join(file_path.split('/')[-1])\n",
    "                print(f'Debería haber un archivo llamado: {file_name} en:\\n{self.base_dir}\\n\\nAgrega este archivo e intenta de nuevo!\\n')\n",
    "\n",
    "\n",
    "    def cool_print(self, text: str, sleep_time: float=0.01) -> None: \n",
    "        '''\n",
    "        Imprimir como si se fuera escribiendo\n",
    "        '''\n",
    "        acum = ''\n",
    "        for x in text: \n",
    "            # Acumular texto\n",
    "            acum += x\n",
    "            # Limpiar pantalla\n",
    "            clear_output(wait=True)\n",
    "            # Esperar un poco para emular efecto de escritura\n",
    "            sleep(sleep_time)\n",
    "            # Imprimir texto acumulado\n",
    "            print(acum)\n",
    "        # Mantener el texto en pantalla\n",
    "        sleep(1)\n",
    "\n",
    "\n",
    "    def get_csv(self, file_path, **kwargs) -> DataFrame: \n",
    "        '''\n",
    "        Obtener tabla a partir de un archivo .csv\n",
    "        '''\n",
    "        file_name = ''.join(str(file_path).split('/')[-1])\n",
    "        try: \n",
    "            df = read_csv(file_path, low_memory=False, **kwargs)\n",
    "            # Obtener el número de renglones y columnas para informar al usuario\n",
    "            df_shape = df.shape\n",
    "            self.cool_print(f'Archivo con nombre {file_name} fue encontrado en:\\n{self.base_dir}\\nCon {df_shape[0]} renglones y {df_shape[-1]} columnas')\n",
    "            df.columns = map(lambda x: str(x).strip().replace(' ','_').lower(), df.columns)\n",
    "            return df\n",
    "        # Informar que hubo error al intentar importar el csv\n",
    "        except: self.cool_print(f'No se encontró el archivo con nombre {file_name} en:\\n{self.base_dir}\\nSi el archivo csv existe, seguramente tiene un encoding y/o separador diferente a \"utf-8\" y \",\" respectivamente\\nIntenta de nuevo!')\n",
    "    \n",
    "\n",
    "    def export_csv(self, df: DataFrame, file_name: str, name_suffix=None, **kwargs) -> None: \n",
    "        '''\n",
    "        Exportar un archivo en formato csv\n",
    "        '''\n",
    "        export_name = f'{file_name}.csv' if name_suffix==None else f'{file_name}_{name_suffix}.csv'\n",
    "        df.to_csv(self.base_dir.joinpath(export_name), **kwargs)\n",
    "        self.cool_print(f'Archivo: {export_name} fue exportado exitosamente en:\\n{self.base_dir}')\n",
    "\n",
    "\n",
    "    def clean_text(self, text: str, pattern: str=\"[^a-zA-Z0-9\\s]\", lower: bool=False) -> str: \n",
    "        '''\n",
    "        Limpieza de texto\n",
    "        '''\n",
    "        # Reemplazar acentos: áàäâã --> a\n",
    "        clean = normalize('NFD', str(text).replace('\\n', ' \\n ')).encode('ascii', 'ignore')\n",
    "        # Omitir caracteres especiales !\"#$%&/()=...\n",
    "        clean = sub(pattern, ' ', clean.decode('utf-8'), flags=UNICODE)\n",
    "        # Mantener sólo un espacio\n",
    "        clean = sub(r'\\s{2,}', ' ', clean.strip())\n",
    "        # Minúsculas si el parámetro lo indica\n",
    "        if lower: clean = clean.lower()\n",
    "        # Si el registro estaba vacío, indicar nulo\n",
    "        if clean in ('','nan'): clean = nan\n",
    "        return clean\n",
    "\n",
    "\n",
    "    def choose_correct(self, df: DataFrame, col: str, correct_list: list, fill_value: str='DESCONOCIDO', **kwargs) -> DataFrame:\n",
    "        '''\n",
    "        Recibe un DataFrame y una lista de posibilidades, especificando la columna a revisar\n",
    "        elige la opción que más se parezca a alguna de las posibilidades\n",
    "        '''\n",
    "        correct_list = list(set(correct_list))\n",
    "        # Aplicar limpieza de texto a la lista de posibilidades\n",
    "        correct_clean = list(map(lambda x: self.clean_text(x, lower=True), correct_list))\n",
    "        # Hacer un diccionario de posibilidades limpias y las originales recibidas\n",
    "        correct_dict = dict(zip(correct_clean, correct_list))\n",
    "\n",
    "        # Aplicar la limpieza a la columna especificada\n",
    "        df[f'{col}_correct'] = df[col].map(lambda x: self.clean_text(x,lower=True))\n",
    "        # Encontrar las posibilidades más parecidas\n",
    "        df[f'{col}_correct'] = df[f'{col}_correct'].map(lambda x: get_close_matches(x, correct_clean, **kwargs))\n",
    "        # Si existen parecidas, traer la primera opción que es la más parecida\n",
    "        df[f'{col}_correct'] = df[f'{col}_correct'].map(lambda x: x[0] if isinstance(x,list) and len(x)>0 else nan)\n",
    "        # Regresar del texto limpio a la posibilidad original, lo no encontrado se llena con \"fill_value\"\n",
    "        df[f'{col}_correct'] = df[f'{col}_correct'].map(correct_dict).fillna(fill_value)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def compare_catalog(self, id_cols: list=['sku','barcodes'], name_cols: list=['name'], export_result: bool=True, n:int=100) -> DataFrame:\n",
    "        df_mx = self.get_csv(self.file_mx)[id_cols+name_cols].sample(n)\n",
    "        df_cl = self.get_csv(self.file_cl)[id_cols+name_cols]\n",
    "        \n",
    "        df = DataFrame()\n",
    "        to_omit = [-1]\n",
    "        for id_col in id_cols:\n",
    "            aux = df_cl.rename({id_col:f'{id_col}_found'}, axis=1)\n",
    "            aux['is_found'] = id_col\n",
    "            without_omit = df_mx.loc[df_mx.index.isin(to_omit)].copy()\n",
    "            to_append = without_omit.merge(aux, left_on=id_col, right_on=f'{id_col}_found', suffixes=('','_found'))\n",
    "            df = df.append(to_append, ignore_index=False)\n",
    "            to_omit.append(to_append.index)\n",
    "\n",
    "        for name_col in name_cols:\n",
    "            aux = df_cl.rename({name_col:f'{name_col}_found'}, axis=1)\n",
    "            aux['is_found'] = name_col\n",
    "            without_omit = df_mx.loc[df_mx.index.isin(to_omit)].copy()\n",
    "            to_find = self.choose_correct(without_omit, name_col, df_cl[name_col], n=1, cutoff=0.85)\n",
    "            to_append = without_omit.merge(to_find, left_on=name_col, right_on=f'{name_col}_correct', how='left', suffixes=('', f'_search_by_{name_col}'))\n",
    "            to_append.drop(f'{name_col}_correct', axis=1, inplace=True)\n",
    "            df = df.append(to_append, ignore_index=False)\n",
    "            to_omit.append(to_append.index)\n",
    "\n",
    "        return df\n",
    "        # if export_result: self.export_csv(acum, file_name='Decathlon', index=False, sep='\\t', encoding='utf-16')\n",
    "        # return acum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo con nombre Decathlon_CL.csv fue encontrado en:\n",
      "/Users/efraflores/Desktop/EF/Corner/Catalog/Decathlon\n",
      "Con 17552 renglones y 12 columnas\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j4/1p33_bh96yn8pdz3b_5t80hm0000gn/T/ipykernel_1502/3195631842.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompareCatalog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFILE_MX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFILE_CL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_catalog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/hub/cornershop/venv/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   5348\u001b[0m             )\n\u001b[1;32m   5349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5350\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "df = CompareCatalog(BASE_DIR, FILE_MX, FILE_CL).compare_catalog()\n",
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku    86\n",
       "Name: is_found, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_found'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd073f3038b8337706d4c7d775204fb19bddc277721f52eb60f8c4b0892f2184"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
