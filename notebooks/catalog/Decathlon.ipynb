{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparar catálogo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/efraflores/Desktop/EF/Corner/Catalog/Decathlon'\n",
    "FILE_MX = 'Decathlon_MX.csv'\n",
    "FILE_CL = 'Decathlon_CL.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control de datos\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Ingeniería de variables\n",
    "from math import sqrt\n",
    "from numpy import nan\n",
    "from collections import Counter\n",
    "from unicodedata import normalize\n",
    "from re import sub, findall, UNICODE\n",
    "from difflib import get_close_matches\n",
    "from pandas import DataFrame, read_csv, options\n",
    "options.mode.chained_assignment = None\n",
    "\n",
    "class CompareCatalog:\n",
    "    def __init__(self, base_dir:str, file_mx: str, file_cl: str) -> None:\n",
    "        '''\n",
    "        Obtener un directorio como texto y convertirlo a tipo Path para unir directorios, buscar archivos, etc.\n",
    "        '''\n",
    "        self.base_dir = Path(base_dir)\n",
    "        # Definir la ruta completa para leer cada archivo\n",
    "        self.file_mx = self.base_dir.joinpath(file_mx)\n",
    "        self.file_cl = self.base_dir.joinpath(file_cl)\n",
    "        # Verificar que existe el archivo en el directorio\n",
    "        for file_path in [self.file_mx, self.file_cl]:\n",
    "            if not file_path.is_file():\n",
    "                file_name = ''.join(file_path.split('/')[-1])\n",
    "                print(f'Debería haber un archivo llamado: {file_name} en:\\n{self.base_dir}\\n\\nAgrega este archivo e intenta de nuevo!\\n')\n",
    "\n",
    "\n",
    "    def cool_print(self, text: str, sleep_time: float=0.01) -> None: \n",
    "        '''\n",
    "        Imprimir como si se fuera escribiendo\n",
    "        '''\n",
    "        acum = ''\n",
    "        for x in text: \n",
    "            # Acumular texto\n",
    "            acum += x\n",
    "            # Limpiar pantalla\n",
    "            clear_output(wait=True)\n",
    "            # Esperar un poco para emular efecto de escritura\n",
    "            sleep(sleep_time)\n",
    "            # Imprimir texto acumulado\n",
    "            print(acum)\n",
    "        # Mantener el texto en pantalla\n",
    "        sleep(1)\n",
    "\n",
    "\n",
    "    def get_csv(self, file_path, **kwargs) -> DataFrame: \n",
    "        '''\n",
    "        Obtener tabla a partir de un archivo .csv\n",
    "        '''\n",
    "        file_name = ''.join(str(file_path).split('/')[-1])\n",
    "        try: \n",
    "            df = read_csv(file_path, low_memory=False, **kwargs)\n",
    "            # Obtener el número de renglones y columnas para informar al usuario\n",
    "            df_shape = df.shape\n",
    "            self.cool_print(f'Archivo con nombre {file_name} fue encontrado en:\\n{self.base_dir}\\nCon {df_shape[0]} renglones y {df_shape[-1]} columnas')\n",
    "            df.columns = map(lambda x: str(x).strip().replace(' ','_').lower(), df.columns)\n",
    "            return df\n",
    "        # Informar que hubo error al intentar importar el csv\n",
    "        except: self.cool_print(f'No se encontró el archivo con nombre {file_name} en:\\n{self.base_dir}\\nSi el archivo csv existe, seguramente tiene un encoding y/o separador diferente a \"utf-8\" y \",\" respectivamente\\nIntenta de nuevo!')\n",
    "    \n",
    "\n",
    "    def export_csv(self, df: DataFrame, file_name: str, name_suffix=None, **kwargs) -> None: \n",
    "        '''\n",
    "        Exportar un archivo en formato csv\n",
    "        '''\n",
    "        export_name = f'{file_name}.csv' if name_suffix==None else f'{file_name}_{name_suffix}.csv'\n",
    "        df.to_csv(self.base_dir.joinpath(export_name), **kwargs)\n",
    "        self.cool_print(f'Archivo: {export_name} fue exportado exitosamente en:\\n{self.base_dir}')\n",
    "\n",
    "\n",
    "    def clean_text(self, text: str, pattern: str=\"[^a-zA-Z0-9\\s]\", lower: bool=False) -> str: \n",
    "        '''\n",
    "        Limpieza de texto\n",
    "        '''\n",
    "        # Reemplazar acentos: áàäâã --> a\n",
    "        clean = normalize('NFD', str(text).replace('\\n', ' \\n ')).encode('ascii', 'ignore')\n",
    "        # Omitir caracteres especiales !\"#$%&/()=...\n",
    "        clean = sub(pattern, ' ', clean.decode('utf-8'), flags=UNICODE)\n",
    "        # Mantener sólo un espacio\n",
    "        clean = sub(r'\\s{2,}', ' ', clean.strip())\n",
    "        # Minúsculas si el parámetro lo indica\n",
    "        if lower: clean = clean.lower()\n",
    "        # Si el registro estaba vacío, indicar nulo\n",
    "        if clean in ('','nan'): clean = nan\n",
    "        return clean\n",
    "\n",
    "\n",
    "    def get_cosine(self, vec1, vec2) -> float:\n",
    "        intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "        numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "        sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
    "        sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
    "        denominator = sqrt(sum1) * sqrt(sum2)\n",
    "\n",
    "        if not denominator:return 0.0\n",
    "        else: return float(numerator) / denominator\n",
    "\n",
    "    def text_to_vector(self, text: str) -> Counter:\n",
    "        words = findall(r\"\\w+\", text)\n",
    "        return Counter(words)\n",
    "\n",
    "    def cosine_sim(self, text_one: str, text_two: str) -> float:\n",
    "        vector1 = self.text_to_vector(text_one)\n",
    "        vector2 = self.text_to_vector(text_two)\n",
    "        return self.get_cosine(vector1, vector2)\n",
    "\n",
    "    def choose_correct(self, df: DataFrame, col: str, correct_list: list, suffix: str='correct', fill_value: str='DESCONOCIDO', **kwargs) -> DataFrame:\n",
    "        '''\n",
    "        Recibe un DataFrame y una lista de posibilidades, especificando la columna a revisar\n",
    "        elige la opción que más se parezca a alguna de las posibilidades\n",
    "        '''\n",
    "        correct_list = list(set(correct_list))\n",
    "        # Aplicar limpieza de texto a la lista de posibilidades\n",
    "        correct_clean = list(map(lambda x: self.clean_text(x, lower=True), correct_list))\n",
    "        # Hacer un diccionario de posibilidades limpias y las originales recibidas\n",
    "        correct_dict = dict(zip(correct_clean, correct_list))\n",
    "\n",
    "        # Aplicar la limpieza a la columna especificada\n",
    "        df[f'{col}_{suffix}'] = df[col].map(lambda x: self.clean_text(x,lower=True))\n",
    "        # Encontrar las posibilidades más parecidas\n",
    "        df[f'{col}_{suffix}'] = df[f'{col}_{suffix}'].map(lambda x: get_close_matches(x, correct_clean, **kwargs))\n",
    "        # Si existen parecidas, traer la primera opción que es la más parecida\n",
    "        df[f'{col}_{suffix}'] = df[f'{col}_{suffix}'].map(lambda x: x[0] if isinstance(x,list) and len(x)>0 else nan)\n",
    "        # Regresar del texto limpio a la posibilidad original, lo no encontrado se llena con \"fill_value\"\n",
    "        df[f'{col}_{suffix}'] = df[f'{col}_{suffix}'].map(correct_dict).fillna(fill_value)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def compare_catalog(self, id_cols: list=['sku','barcodes'], name_cols: list=['name'], export_result: bool=True) -> DataFrame:\n",
    "        '''\n",
    "        Compara dos catálogos empezando con coincidencia exacta de \"id_cols\" y después coincidencia aproximada de \"name_cols\"\n",
    "        '''\n",
    "        # Importa ambos catálogos\n",
    "        df_mx = self.get_csv(self.file_mx)[id_cols+name_cols]\n",
    "        df_cl = self.get_csv(self.file_cl)[id_cols+name_cols]\n",
    "\n",
    "        # Variables auxiliares para acumular resultado\n",
    "        df = DataFrame()\n",
    "        to_omit = []\n",
    "        for col in id_cols+name_cols:\n",
    "            # Omitir índices que ya se han encontrado\n",
    "            without_omit = df_mx.loc[~df_mx.index.isin(to_omit),:].copy()\n",
    "            if col in name_cols: \n",
    "                # Encuentra el texto más parecido del 2o catálogo vs el 1er catálogo\n",
    "                df_cl_copy = self.choose_correct(df_cl.copy(), col, correct_list=without_omit[col], n=1, cutoff=0.85)\n",
    "                # Guarda el nombre más parecido de 2 pero va a unir con el nombre de 1\n",
    "                df_cl_copy.rename({col:f'found_by_{col}',f'{col}_correct':col}, axis=1, inplace=True)\n",
    "            \n",
    "            # Renombra la variable con la que unirá\n",
    "            try: aux = df_cl_copy.rename({col:f'{col}_found'}, axis=1)\n",
    "            except: aux = df_cl.rename({col:f'{col}_found'}, axis=1)\n",
    "            # Indica por qué variable fue encontrado dicho registro\n",
    "            aux['was_found_by'] = col\n",
    "\n",
    "            # Une ambos catálogos \n",
    "            to_append = without_omit.merge(aux, left_on=col, right_on=f'{col}_found', suffixes=('','_found'))\n",
    "\n",
    "            # Apila el resultado de la variable analizada\n",
    "            df = df.append(to_append, ignore_index=False)\n",
    "            # Agrega los índices que deberá omitir en la siguiente iteración\n",
    "            to_omit.append(to_append.index)\n",
    "\n",
    "        for col in name_cols:\n",
    "            # Reemplazar el nombre que más se parecía\n",
    "            aux = []\n",
    "            for found_by, original, found in zip(df['was_found_by'], df[f'{col}_found'], df[f'found_by_{col}']):\n",
    "                if found_by == col: aux.append(found)\n",
    "                else: aux.append(original)\n",
    "            df[f'{col}_found'] = aux\n",
    "\n",
    "            # Omitir la columna para mantener la estructura\n",
    "            df.drop(f'found_by_{col}', axis=1, inplace=True)\n",
    "\n",
    "            # Obtener el parecido del nombre original vs el encontrado\n",
    "            df[f'{col}_similarity'] = df[[col,f'{col}_found']].apply(lambda x: self.cosine_sim(x[0],x[-1]), axis=1)\n",
    "\n",
    "        # Omitir duplicados\n",
    "        df = df.sort_values([id_cols[0],f'{name_cols[0]}_found']).drop_duplicates(id_cols[0])\n",
    "\n",
    "        # Exportar el resultado\n",
    "        if export_result: self.export_csv(df, file_name='Decathlon', index=False, sep='\\t', encoding='utf-16')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: Decathlon.csv fue exportado exitosamente en:\n",
      "/Users/efraflores/Desktop/EF/Corner/Catalog/Decathlon\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>barcodes</th>\n",
       "      <th>name</th>\n",
       "      <th>sku_found</th>\n",
       "      <th>barcodes_found</th>\n",
       "      <th>name_found</th>\n",
       "      <th>was_found_by</th>\n",
       "      <th>name_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>1273231</td>\n",
       "      <td>3.583789e+12</td>\n",
       "      <td>Botas Caza Solognac Renfort 500 Verde Solognac</td>\n",
       "      <td>1273231</td>\n",
       "      <td>3.583790e+12</td>\n",
       "      <td>Bota De Caza Renfort 500</td>\n",
       "      <td>sku</td>\n",
       "      <td>0.447214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>631234</td>\n",
       "      <td>3.608460e+12</td>\n",
       "      <td>Panty Bikini Surf Olaian Lazos Sofy Negra Muje...</td>\n",
       "      <td>631234</td>\n",
       "      <td>3.608460e+12</td>\n",
       "      <td>Parte Inferior De Bikini De Surf Mujer Anudada...</td>\n",
       "      <td>sku</td>\n",
       "      <td>0.311400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2413581</td>\n",
       "      <td>3.583788e+12</td>\n",
       "      <td>Balón De Balonmano H100 Soft T1 Azul Y Amarillo</td>\n",
       "      <td>2413581</td>\n",
       "      <td>3.583790e+12</td>\n",
       "      <td>Balon De Handball H100 Soft T1</td>\n",
       "      <td>sku</td>\n",
       "      <td>0.544331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12568</th>\n",
       "      <td>2505923</td>\n",
       "      <td>3.608430e+12</td>\n",
       "      <td>Tenis De Running Hombre Run Active Azul Oscuro...</td>\n",
       "      <td>2505923</td>\n",
       "      <td>3.608430e+12</td>\n",
       "      <td>Zapatillas De Running Para Hombre Run Active</td>\n",
       "      <td>sku</td>\n",
       "      <td>0.629941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>2665416</td>\n",
       "      <td>3.583788e+12</td>\n",
       "      <td>Guantes Portero De Fútbol Kipsta F500 Niños Az...</td>\n",
       "      <td>2665416</td>\n",
       "      <td>3.583790e+12</td>\n",
       "      <td>Guantes Arquero De Futbol F500 Ninos</td>\n",
       "      <td>sku</td>\n",
       "      <td>0.339683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14975</th>\n",
       "      <td>2777020</td>\n",
       "      <td>3.608410e+12</td>\n",
       "      <td>Xc 100 29\" Rr Cn Fr Rockrider</td>\n",
       "      <td>2777020</td>\n",
       "      <td>3.608410e+12</td>\n",
       "      <td>Xc 100 29 Rr Cn Fr</td>\n",
       "      <td>sku</td>\n",
       "      <td>0.925820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>2342398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mallas Largas Atletismo Hombre Run Warm Negro</td>\n",
       "      <td>2342398</td>\n",
       "      <td>3.608430e+12</td>\n",
       "      <td>Calzas Largas Running Run Warm Hombre</td>\n",
       "      <td>sku</td>\n",
       "      <td>0.617213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sku      barcodes  \\\n",
       "897    1273231  3.583789e+12   \n",
       "8374    631234  3.608460e+12   \n",
       "533    2413581  3.583788e+12   \n",
       "12568  2505923  3.608430e+12   \n",
       "5005   2665416  3.583788e+12   \n",
       "14975  2777020  3.608410e+12   \n",
       "6042   2342398           NaN   \n",
       "\n",
       "                                                    name  sku_found  \\\n",
       "897       Botas Caza Solognac Renfort 500 Verde Solognac    1273231   \n",
       "8374   Panty Bikini Surf Olaian Lazos Sofy Negra Muje...     631234   \n",
       "533      Balón De Balonmano H100 Soft T1 Azul Y Amarillo    2413581   \n",
       "12568  Tenis De Running Hombre Run Active Azul Oscuro...    2505923   \n",
       "5005   Guantes Portero De Fútbol Kipsta F500 Niños Az...    2665416   \n",
       "14975                      Xc 100 29\" Rr Cn Fr Rockrider    2777020   \n",
       "6042       Mallas Largas Atletismo Hombre Run Warm Negro    2342398   \n",
       "\n",
       "       barcodes_found                                         name_found  \\\n",
       "897      3.583790e+12                           Bota De Caza Renfort 500   \n",
       "8374     3.608460e+12  Parte Inferior De Bikini De Surf Mujer Anudada...   \n",
       "533      3.583790e+12                     Balon De Handball H100 Soft T1   \n",
       "12568    3.608430e+12       Zapatillas De Running Para Hombre Run Active   \n",
       "5005     3.583790e+12               Guantes Arquero De Futbol F500 Ninos   \n",
       "14975    3.608410e+12                                 Xc 100 29 Rr Cn Fr   \n",
       "6042     3.608430e+12              Calzas Largas Running Run Warm Hombre   \n",
       "\n",
       "      was_found_by  name_similarity  \n",
       "897            sku         0.447214  \n",
       "8374           sku         0.311400  \n",
       "533            sku         0.544331  \n",
       "12568          sku         0.629941  \n",
       "5005           sku         0.339683  \n",
       "14975          sku         0.925820  \n",
       "6042           sku         0.617213  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = CompareCatalog(BASE_DIR, FILE_MX, FILE_CL).compare_catalog()\n",
    "df.sample(7)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd073f3038b8337706d4c7d775204fb19bddc277721f52eb60f8c4b0892f2184"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
