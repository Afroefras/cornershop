{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chat_404.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1xBQ0JcaPUjK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMZNiy7WPW2j"
      },
      "source": [
        "## Parámetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-jYRyO5PY9O"
      },
      "source": [
        "# Directorio de los resultados de la query\n",
        "BASE_DIR = '/content'\n",
        "# Nombre base, es decir, puede haber varios archivos con \"nombre_0\", \"nombre_1\", etc y el nombre base sería \"nombre\"\n",
        "FILE_BASE_NAME = 'fantasias'\n",
        "# Palabras para buscar en el chat\n",
        "WORDS = 'no encuentro, no encontrado, no hay'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xBQ0JcaPUjK"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po-JZWTzPTRR"
      },
      "source": [
        "from json import loads\n",
        "from typing import Dict\n",
        "from pathlib import Path\n",
        "from unicodedata import normalize\n",
        "from re import UNICODE, search, sub, findall\n",
        "from pandas import DataFrame, read_csv, json_normalize, to_datetime, cut\n",
        "\n",
        "class ChatNotFound:\n",
        "    def __init__(self, base_dir: str, file_base_name: str, words: str) -> None:\n",
        "        self.base_dir = Path(base_dir)\n",
        "        self.words = words\n",
        "        self.file_name = file_base_name\n",
        "        self.files_list = [x for x in self.base_dir.glob('*') if search(f'{self.file_name}_(?!found)', str(x))]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.files_list)\n",
        "    \n",
        "    def __str__(self) -> str:\n",
        "        return f'Directorio: {self.base_dir}\\nCon {self.__len__()} archivo(s) para buscar las palabras:\\n{self.words}'\n",
        "\n",
        "    def read_files(self) -> DataFrame:\n",
        "        df = DataFrame()\n",
        "        for file_chunk in self.files_list:\n",
        "            df = df.append(read_csv(file_chunk), ignore_index=True)\n",
        "        return df\n",
        "\n",
        "    def date_vars(self, df: DataFrame, cols: list=['date']) -> DataFrame:\n",
        "        for col in cols:\n",
        "            df[col] = to_datetime(df[col], yearfirst=True)\n",
        "            df[f'{col}_year'] = df[col].dt.year\n",
        "            df[f'{col}_month'] = df[f'{col}_year'].astype(str)+'-'+df[col].dt.month.astype(str).str.zfill(2)\n",
        "            df[f'{col}_week'] = df[f'{col}_year'].astype(str)+'-'+df[col].dt.isocalendar().week.astype(str).str.zfill(2)        \n",
        "            df[f'{col}_dayname'] = df[col].dt.day_name().str[:3]\n",
        "            df[f'{col}_hour'] = df[col].dt.hour.astype(str).str.zfill(2)\n",
        "            df[f'{col}_hour_range'] = cut(df[col].dt.hour, bins=[-1,8,12,16,20,23])\n",
        "            df[f'{col}_hour_range'] = df[f'{col}_hour_range'].map(lambda x: str(x.left+1).zfill(2)+' to '+str(x.right).zfill(2))\n",
        "        return df\n",
        "\n",
        "    def get_chat(self, x: str) -> Dict:\n",
        "        expanded_json = json_normalize(loads(x))\n",
        "        separated_roles = expanded_json.pivot_table(columns='user.metadata.role', aggfunc={'message':'--'.join})\n",
        "        correct_dict = {}\n",
        "        for col in separated_roles.columns:\n",
        "            try: correct_dict[col] = separated_roles.to_dict()[col]['message']\n",
        "            except: pass\n",
        "        return correct_dict\n",
        "\n",
        "    def clean_text(self, text: str, pattern: str=\"[^a-zA-Z\\s]\", lower: bool=False, lemma: bool=False, rem_stopw: bool=False, unique: bool=False) -> str:\n",
        "        cleaned_text = normalize('NFD',str(text).replace('\\n',' \\n ')).encode('ascii', 'ignore')\n",
        "        cleaned_text = sub(pattern,' ',cleaned_text.decode('utf-8'), flags=UNICODE)\n",
        "        cleaned_text = [word for word in (cleaned_text.lower().split() if lower else cleaned_text.split())]\n",
        "        return ' '.join((set(cleaned_text) if unique else cleaned_text))\n",
        "\n",
        "    def find_words(self, x, to_find):\n",
        "        return findall('|'.join(map(lambda x: x.strip().lower(), to_find.split(','))),x)\n",
        "\n",
        "    def var_msg(self, df: DataFrame, cols: str=['customer','shopper'], **kwargs) -> DataFrame:\n",
        "        for col in cols:\n",
        "            df[f'n_msg_{col}'] = df[col].str.split('--').str.len()\n",
        "            df[f'n_words_{col}'] = df[col].str.replace('--',' ').str.split().str.len()\n",
        "            df[f'clean_{col}'] = df[col].map(lambda x: self.clean_text(str(x), **kwargs))\n",
        "            df[f'found_{col}'] = df[f'clean_{col}'].map(lambda x: self.find_words(x, self.words))\n",
        "            df[f'n_found_{col}'] = df[f'found_{col}'].map(len)\n",
        "            df.fillna({x:0 for x in df.head(1).filter(like=f'_{col}')}, inplace=True)\n",
        "        df['found_pattern'] = (df.filter(like='n_found_').sum(axis=1) > 0)*1\n",
        "        return df\n",
        "    \n",
        "    def export_csv(self, df: DataFrame, name_suffix=None, **kwargs) -> None:\n",
        "        export_name = f'{self.file_name}.csv' if name_suffix==None else f'{self.file_name}_{name_suffix}.csv'\n",
        "        df.to_csv(self.base_dir.joinpath(export_name), **kwargs)\n",
        "\n",
        "    def full_pipeline(self) -> DataFrame:\n",
        "        df = self.read_files()\n",
        "        df = self.date_vars(df)\n",
        "        df = df.join(DataFrame(df['messages'].map(self.get_chat).tolist(), index=df.index)).drop('messages', axis=1)\n",
        "        df = self.var_msg(df, pattern=\"[^a-zA-Z0-9\\s\\-]\", lower=True)\n",
        "        self.export_csv(df, name_suffix='found', index=False, sep='\\t', encoding='utf-16')\n",
        "        return df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRW5RnkTjfm3"
      },
      "source": [
        "## Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k6Qlj05m0bm",
        "outputId": "0ea45d66-0873-4687-fd34-9ac7b7724de3"
      },
      "source": [
        "cnf = ChatNotFound(BASE_DIR, FILE_BASE_NAME, WORDS)\n",
        "print(cnf)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path: /content\n",
            "With 1 files to check for words:\n",
            "no encuentro, no encontrado, no hay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "bI0T8Tqti2v7",
        "outputId": "5d6dd9fe-b77e-472a-dae4-111dbe33a053"
      },
      "source": [
        "df = cnf.full_pipeline()\n",
        "df.sample()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>date</th>\n",
              "      <th>city</th>\n",
              "      <th>store_id</th>\n",
              "      <th>store</th>\n",
              "      <th>branch_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>products_not_found</th>\n",
              "      <th>date_year</th>\n",
              "      <th>date_month</th>\n",
              "      <th>date_week</th>\n",
              "      <th>date_dayname</th>\n",
              "      <th>date_hour</th>\n",
              "      <th>date_hour_range</th>\n",
              "      <th>customer</th>\n",
              "      <th>shopper</th>\n",
              "      <th>n_msg_customer</th>\n",
              "      <th>n_words_customer</th>\n",
              "      <th>clean_customer</th>\n",
              "      <th>found_customer</th>\n",
              "      <th>n_found_customer</th>\n",
              "      <th>n_msg_shopper</th>\n",
              "      <th>n_words_shopper</th>\n",
              "      <th>clean_shopper</th>\n",
              "      <th>found_shopper</th>\n",
              "      <th>n_found_shopper</th>\n",
              "      <th>found_pattern</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>43032664</td>\n",
              "      <td>2021-10-06 14:14:22.551461</td>\n",
              "      <td>Ciudad de México</td>\n",
              "      <td>146</td>\n",
              "      <td>Fantasías Miguel</td>\n",
              "      <td>1214</td>\n",
              "      <td>1251975</td>\n",
              "      <td>Pick OtoÃ±al Calabazas 22cm  - OtoÃ±o</td>\n",
              "      <td>2021</td>\n",
              "      <td>2021-10</td>\n",
              "      <td>2021-40</td>\n",
              "      <td>Wed</td>\n",
              "      <td>14</td>\n",
              "      <td>13 to 16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>María Leticia is on their way with your order-...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nan</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>maria leticia is on their way with your order-...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    order_id                       date  ... n_found_shopper  found_pattern\n",
              "25  43032664 2021-10-06 14:14:22.551461  ...               0              0\n",
              "\n",
              "[1 rows x 27 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}