{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMZNiy7WPW2j"
      },
      "source": [
        "## Parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m-jYRyO5PY9O"
      },
      "outputs": [],
      "source": [
        "# Directorio de los resultados de la query\n",
        "BASE_DIR = '/Users/efraflores/Downloads'\n",
        "# Nombre base, es decir, puede haber varios archivos con \"nombre_0\", \"nombre_1\", etc y el nombre base sería \"nombre\"\n",
        "FILE_BASE_NAME = 'Mensajes'\n",
        "# Palabras para buscar en el chat\n",
        "WORDS = 'reciclar las bolsas Cornershop'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xBQ0JcaPUjK"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "po-JZWTzPTRR"
      },
      "outputs": [],
      "source": [
        "from json import loads\n",
        "from typing import Dict\n",
        "from pathlib import Path\n",
        "from unicodedata import normalize\n",
        "from re import UNICODE, search, sub, findall\n",
        "from pandas import DataFrame, read_csv, json_normalize, to_datetime, cut\n",
        "\n",
        "class ChatNotFound:\n",
        "    def __init__(self, base_dir: str, file_base_name: str, words: str) -> None:\n",
        "        self.base_dir = Path(base_dir)\n",
        "        self.words = words\n",
        "        self.file_name = file_base_name\n",
        "        self.files_list = [x for x in self.base_dir.glob('*') if search(f'{self.file_name}_(?!found)', str(x))]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.files_list)\n",
        "    \n",
        "    def __str__(self) -> str:\n",
        "        return f'Directorio: {self.base_dir}\\nCon {self.__len__()} archivo(s) para buscar las palabras:\\n\"{self.words}\"'\n",
        "\n",
        "    def read_files(self) -> DataFrame:\n",
        "        df = DataFrame()\n",
        "        for file_chunk in self.files_list:\n",
        "            df = df.append(read_csv(file_chunk), ignore_index=True)\n",
        "        return df\n",
        "\n",
        "    def date_vars(self, df: DataFrame, cols: list=['date']) -> DataFrame:\n",
        "        for col in cols:\n",
        "            df[col] = to_datetime(df[col], yearfirst=True)\n",
        "            df[f'{col}_year'] = df[col].dt.year\n",
        "            df[f'{col}_month'] = df[f'{col}_year'].astype(str)+'-'+df[col].dt.month.astype(str).str.zfill(2)\n",
        "            df[f'{col}_week'] = df[f'{col}_year'].astype(str)+'-'+df[col].dt.isocalendar().week.astype(str).str.zfill(2)        \n",
        "            df[f'{col}_dayname'] = df[col].dt.day_name().str[:3]\n",
        "            df[f'{col}_hour'] = df[col].dt.hour.astype(str).str.zfill(2)\n",
        "            df[f'{col}_hour_range'] = cut(df[col].dt.hour, bins=[-1,8,12,16,20,23])\n",
        "            df[f'{col}_hour_range'] = df[f'{col}_hour_range'].map(lambda x: str(x.left+1).zfill(2)+' to '+str(x.right).zfill(2))\n",
        "        return df\n",
        "\n",
        "    def get_chat(self, x: str) -> Dict:\n",
        "        expanded_json = json_normalize(loads(x))\n",
        "        correct_dict = {}\n",
        "        try: separated_roles = expanded_json.pivot_table(columns='user.metadata.role', aggfunc={'message':'--'.join})\n",
        "        except: return correct_dict\n",
        "        for col in separated_roles.columns:\n",
        "            try: correct_dict[col] = separated_roles.to_dict()[col]['message']\n",
        "            except: pass\n",
        "        return correct_dict\n",
        "\n",
        "    def clean_text(self, text: str, pattern: str=\"[^a-zA-Z\\s]\", lower: bool=False, lemma: bool=False, rem_stopw: bool=False, unique: bool=False) -> str:\n",
        "        cleaned_text = normalize('NFD',str(text).replace('\\n',' \\n ')).encode('ascii', 'ignore')\n",
        "        cleaned_text = sub(pattern,' ',cleaned_text.decode('utf-8'), flags=UNICODE)\n",
        "        cleaned_text = [word for word in (cleaned_text.lower().split() if lower else cleaned_text.split())]\n",
        "        return ' '.join((set(cleaned_text) if unique else cleaned_text))\n",
        "\n",
        "    def find_words(self, x, to_find):\n",
        "        return findall('|'.join(map(lambda x: x.strip().lower(), to_find.split(','))),x)\n",
        "\n",
        "    def var_msg(self, df: DataFrame, cols: str=['customer','shopper'], **kwargs) -> DataFrame:\n",
        "        for col in cols:\n",
        "            df[f'n_msg_{col}'] = df[col].str.split('--').str.len()\n",
        "            df[f'n_words_{col}'] = df[col].str.replace('--',' ').str.split().str.len()\n",
        "            df[f'clean_{col}'] = df[col].map(lambda x: self.clean_text(str(x), **kwargs))\n",
        "            df[f'found_{col}'] = df[f'clean_{col}'].map(lambda x: self.find_words(x, self.words))\n",
        "            df[f'n_found_{col}'] = df[f'found_{col}'].map(len)\n",
        "            df.fillna({x:0 for x in df.head(1).filter(like=f'_{col}')}, inplace=True)\n",
        "        df['found_pattern'] = (df.filter(like='n_found_').sum(axis=1) > 0)*1\n",
        "        return df\n",
        "    \n",
        "    def export_csv(self, df: DataFrame, name_suffix=None, **kwargs) -> None:\n",
        "        export_name = f'{self.file_name}.csv' if name_suffix==None else f'{self.file_name}_{name_suffix}.csv'\n",
        "        df.to_csv(self.base_dir.joinpath(export_name), **kwargs)\n",
        "\n",
        "    def full_pipeline(self) -> DataFrame:\n",
        "        df = self.read_files()\n",
        "        # df = self.date_vars(df)\n",
        "        found = DataFrame(df['messages'].map(self.get_chat).tolist(), index=df.index)\n",
        "        df = df.join(found).drop('messages', axis=1)\n",
        "        df = self.var_msg(df, pattern=\"[^a-zA-Z0-9\\s\\-]\", lower=True)\n",
        "        self.export_csv(df, name_suffix='found', index=False, sep='\\t', encoding='utf-16')\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRW5RnkTjfm3"
      },
      "source": [
        "## Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k6Qlj05m0bm",
        "outputId": "0ea45d66-0873-4687-fd34-9ac7b7724de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directorio: /Users/efraflores/Downloads\n",
            "Con 1 archivo(s) para buscar las palabras:\n",
            "\"reciclar las bolsas Cornershop\"\n"
          ]
        }
      ],
      "source": [
        "cnf = ChatNotFound(BASE_DIR, FILE_BASE_NAME, WORDS)\n",
        "print(cnf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "bI0T8Tqti2v7",
        "outputId": "5d6dd9fe-b77e-472a-dae4-111dbe33a053"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>customer</th>\n",
              "      <th>shopper</th>\n",
              "      <th>n_msg_customer</th>\n",
              "      <th>n_words_customer</th>\n",
              "      <th>clean_customer</th>\n",
              "      <th>found_customer</th>\n",
              "      <th>n_found_customer</th>\n",
              "      <th>n_msg_shopper</th>\n",
              "      <th>n_words_shopper</th>\n",
              "      <th>clean_shopper</th>\n",
              "      <th>found_shopper</th>\n",
              "      <th>n_found_shopper</th>\n",
              "      <th>found_pattern</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12402</th>\n",
              "      <td>45574087</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Luis Antonio está en camino con tu pedido--jso...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nan</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>luis antonio esta en camino con tu pedido--jso...</td>\n",
              "      <td>[reciclar las bolsas cornershop]</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id customer                                            shopper  \\\n",
              "12402  45574087      NaN  Luis Antonio está en camino con tu pedido--jso...   \n",
              "\n",
              "       n_msg_customer  n_words_customer clean_customer found_customer  \\\n",
              "12402             0.0               0.0            nan             []   \n",
              "\n",
              "       n_found_customer  n_msg_shopper  n_words_shopper  \\\n",
              "12402                 0            7.0            122.0   \n",
              "\n",
              "                                           clean_shopper  \\\n",
              "12402  luis antonio esta en camino con tu pedido--jso...   \n",
              "\n",
              "                          found_shopper  n_found_shopper  found_pattern  \n",
              "12402  [reciclar las bolsas cornershop]                1              1  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = cnf.full_pipeline()\n",
        "df[df['found_pattern']>0].sample()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1xBQ0JcaPUjK"
      ],
      "name": "Chat_404.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
