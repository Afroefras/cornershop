{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/efraflores/Desktop/EF/Corner/Requests'\n",
    "FILE_NAME = 'custom_products.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "from numpy import nan\n",
    "from emoji import demojize\n",
    "from re import sub, UNICODE\n",
    "from unicodedata import normalize\n",
    "from pandas import DataFrame, ExcelWriter, read_csv\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class CustomProducts:\n",
    "    def __init__(self, base_dir: str, csv_file: str, stop_words: list=[]) -> None:\n",
    "        self.stopwords = stop_words\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.csv_path = self.base_dir.joinpath(csv_file)\n",
    "        self.csv_name = ''.join(csv_file.split('.')[:-1])\n",
    "\n",
    "        if not self.csv_path.is_file():\n",
    "            print(f'There should be a file called: {self.csv_name} at:\\n{self.base_dir}\\n\\nAdd it and try again!')\n",
    "\n",
    "    def clean_text(self, text: str, rem_stop: list, pattern: str=\"[^a-zA-Z\\s]\", lower: bool=True, emoji: bool=True, to_singular: bool=True) -> str: \n",
    "        '''\n",
    "        Limpieza de texto\n",
    "        '''\n",
    "        # \"Traduce\" emojis, ej: 游쓇릖 --> :Mexico:\n",
    "        if emoji: text = demojize(text)\n",
    "\n",
    "        # Reemplazar acentos: 치먞뱪뭮 --> a\n",
    "        clean = normalize('NFD', str(text).replace('\\n', ' \\n ')).encode('ascii', 'ignore')\n",
    "        # Omitir caracteres especiales !\"#$%&/()=...\n",
    "        clean = sub(pattern, ' ', clean.decode('utf-8'), flags=UNICODE)\n",
    "\n",
    "        # Mantener s칩lo un espacio\n",
    "        clean = sub(r'\\s{2,}', ' ', clean.strip())\n",
    "\n",
    "        # Min칰sculas si el par치metro lo indica\n",
    "        if lower: clean = clean.lower()\n",
    "        # Omitir la 칰ltima \"s\" si el par치metro lo indica\n",
    "        if to_singular: clean = sub('s\\s',' ',clean+' ')\n",
    "\n",
    "        # Omitir las stopwords indicadas\n",
    "        clean = ' '.join([x for x in clean.split() if x not in rem_stop])\n",
    "\n",
    "        # Si el registro estaba vac칤o, indicar nulo\n",
    "        if clean in ('','nan'): clean = nan\n",
    "        return clean\n",
    "\n",
    "    def get_top(self, df: DataFrame, col: str='description', top_n=100, **kwargs) -> DataFrame:\n",
    "        df[f'{col}_clean'] = df[col].map(lambda x: self.clean_text(str(x), rem_stop=self.stopwords)).fillna('')\n",
    "        cv = CountVectorizer(max_features=top_n, **kwargs)\n",
    "        cv_fit = cv.fit_transform(df[f'{col}_clean'])\n",
    "        top = dict(zip(cv.get_feature_names(), cv_fit.toarray().sum(axis=0)))\n",
    "        top = DataFrame(top, index=['word_count']).T.sort_values('word_count', ascending=False)\n",
    "        return top\n",
    "\n",
    "    def summary(self, top_n: int=50, id_col: str='order_id', name_col: str='custom_product', found_col: str='was_found', replaced_col: str='was_replaced', replaced_by_col: str='replaced_by', custom_found_col: str='quantity_found', total_requested_col: str='qty_products_found', **kwargs) -> None:\n",
    "        df = read_csv(self.csv_path)\n",
    "\n",
    "        n_orders = len(df[id_col].drop_duplicates())\n",
    "        no_dupli_orders = df.sort_values(name_col).drop_duplicates(id_col)\n",
    "\n",
    "        non_custom = no_dupli_orders[name_col].isnull().sum()\n",
    "        tot_custom = n_orders - non_custom\n",
    "        perc_custom = \"{:.2%}\".format(1-non_custom/n_orders)\n",
    "        print(f'\\nSummary:\\n\\nTotal orders:\\t{n_orders}\\nTotal custom:\\t{tot_custom}\\n% orders with custom products:\\t{perc_custom}')\n",
    "\n",
    "        df = df[df[name_col].notnull()].copy()\n",
    "        n_custom = len(df)\n",
    "\n",
    "        print(f'% custom products / products requested:\\t{\"{:.2%}\".format(df[custom_found_col].sum()/df[total_requested_col].sum())}\\n')\n",
    "\n",
    "        df_replaced = df[df[replaced_col]].copy()\n",
    "        df_found = df[df[found_col]].copy()\n",
    "        df_not_replaced = df_found[df_found[replaced_col]==False].copy()\n",
    "        df_not_found = df[df[found_col]==False].copy()\n",
    "        \n",
    "        perc_replaced = \"{:.2%}\".format(len(df_replaced)/n_custom)\n",
    "        perc_not_replaced = \"{:.2%}\".format(len(df_not_replaced)/n_custom)\n",
    "        perc_not_found = \"{:.2%}\".format(len(df_not_found)/n_custom)\n",
    "\n",
    "        writer = ExcelWriter(self.base_dir.joinpath(f'{self.csv_name}.xlsx'), engine='xlsxwriter')\n",
    "        print(f'From the {n_custom} custom products:\\n- {len(df_replaced)} ({perc_replaced}) were replaced\\n- {len(df_not_replaced)} ({perc_not_replaced}) were not replaced but found\\n- {len(df_not_found)} ({perc_not_found}) were not found\\n')        \n",
    "\n",
    "        for name, col, data in zip(['replaced','not replaced','not found'], [replaced_by_col,name_col,name_col], [df_replaced, df_not_replaced, df_not_found]):\n",
    "            print(f'\\nTOP 5 from {name} products:')\n",
    "            df_top = self.get_top(data, col=col, top_n=top_n, **kwargs)\n",
    "            display(df_top.head(5))\n",
    "            df_top.to_excel(writer, sheet_name=name)\n",
    "        writer.save()\n",
    "        print(f'\\nAn Excel file was exported succesfully at:\\n{self.base_dir}\\nEach sheet contains the top {top_n} products')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "\n",
      "Total orders:\t432305\n",
      "Total custom:\t100316\n",
      "% orders with custom products:\t23.20%\n",
      "% custom products / products requested:\t5.90%\n",
      "\n",
      "From the 158656 custom products:\n",
      "- 79449 (50.08%) were replaced\n",
      "- 51907 (32.72%) were not replaced but found\n",
      "- 27300 (17.21%) were not found\n",
      "\n",
      "\n",
      "TOP 5 from replaced products:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pollo</th>\n",
       "      <td>4366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pechuga</th>\n",
       "      <td>3167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>organico</th>\n",
       "      <td>2476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manzana</th>\n",
       "      <td>2130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tortilla</th>\n",
       "      <td>2091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word_count\n",
       "pollo           4366\n",
       "pechuga         3167\n",
       "organico        2476\n",
       "manzana         2130\n",
       "tortilla        2091"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOP 5 from not replaced products:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pechuga</th>\n",
       "      <td>2471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pollo</th>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pavo</th>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pechuga pavo</th>\n",
       "      <td>1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tortilla</th>\n",
       "      <td>1483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word_count\n",
       "pechuga             2471\n",
       "pollo               1994\n",
       "pavo                1931\n",
       "pechuga pavo        1501\n",
       "tortilla            1483"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOP 5 from not found products:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marca</th>\n",
       "      <td>1733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paquete</th>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pechuga</th>\n",
       "      <td>1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bolsa</th>\n",
       "      <td>1328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pavo</th>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word_count\n",
       "marca          1733\n",
       "paquete        1658\n",
       "pechuga        1499\n",
       "bolsa          1328\n",
       "pavo           1257"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An Excel file was exported succesfully at:\n",
      "/Users/efraflores/Desktop/EF/Corner/Requests\n",
      "Each sheet contains the top 50 products\n"
     ]
    }
   ],
   "source": [
    "STOPWORDS = [\n",
    "    'de', 'la', 'que', 'con', 'sin', 'en', 'lo', 'el', 'la', 'un', 'una', 'si', 'no', 'se', 'do',\n",
    "    'pieza', 'kilo', 'kg', 'gr',\n",
    "    'para', 're', 'por', 'favor', 'hay', 'muy', 'gracia',\n",
    "]\n",
    "\n",
    "cp = CustomProducts(BASE_DIR, FILE_NAME, STOPWORDS)\n",
    "df = cp.summary(ngram_range=(1,3))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd073f3038b8337706d4c7d775204fb19bddc277721f52eb60f8c4b0892f2184"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
